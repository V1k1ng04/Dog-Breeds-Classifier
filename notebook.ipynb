{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set has been extracted.\n",
      "Epoch 1/10\n",
      "272/272 [==============================] - 31s 73ms/step - loss: 4.0233 - auc: 0.7806 - val_loss: 2.7013 - val_auc: 0.9311 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 2.7630 - auc: 0.9256 - val_loss: 2.3033 - val_auc: 0.9499 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 2.2714 - auc: 0.9463 - val_loss: 2.2168 - val_auc: 0.9455 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.9396 - auc: 0.9611 - val_loss: 2.2022 - val_auc: 0.9412 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.6621 - auc: 0.9691 - val_loss: 2.2536 - val_auc: 0.9360 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sb \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from keras import layers \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.model_selection import train_test_split \n",
    "from zipfile import ZipFile \n",
    "import cv2 \n",
    "import joblib\n",
    "import albumentations as A \n",
    "from functools import partial \n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore') \n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Data extraction\n",
    "data_path = 'C:/Users/Satvik/Documents/dev/Dog Breed classification/dog-breed-identification.zip'\n",
    "with ZipFile(data_path, 'r') as zip: \n",
    "    zip.extractall() \n",
    "    print('The data set has been extracted.') \n",
    "\n",
    "# Data preparation\n",
    "df = pd.read_csv('labels.csv') \n",
    "df['filepath'] = 'train/' + df['id'] + '.jpg'\n",
    "\n",
    "le = LabelEncoder() \n",
    "df['breed'] = le.fit_transform(df['breed']) \n",
    "joblib.dump(le, 'label_encoder.pkl')\n",
    "\n",
    "features = df['filepath'] \n",
    "target = df['breed'] \n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(features, target, test_size=0.15, random_state=10) \n",
    "\n",
    "transforms_train = A.Compose([ \n",
    "    A.VerticalFlip(p=0.2), \n",
    "    A.HorizontalFlip(p=0.7), \n",
    "    A.CoarseDropout(p=0.5), \n",
    "    A.RandomGamma(p=0.5), \n",
    "    A.RandomBrightnessContrast(p=1) \n",
    "]) \n",
    "\n",
    "def aug_fn(img): \n",
    "    aug_data = transforms_train(image=img) \n",
    "    aug_img = aug_data['image'] \n",
    "    return aug_img \n",
    "\n",
    "@tf.function \n",
    "def process_data(img, label): \n",
    "    aug_img = tf.numpy_function(aug_fn, [img], Tout=tf.float32) \n",
    "    return aug_img, label \n",
    "\n",
    "def decode_image(filepath, label=None): \n",
    "    img = tf.io.read_file(filepath) \n",
    "    img = tf.image.decode_jpeg(img) \n",
    "    img = tf.image.resize(img, [128, 128]) \n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    if label is None: \n",
    "        return img \n",
    "    return img, tf.one_hot(indices=label, depth=120, dtype=tf.float32) \n",
    "\n",
    "train_ds = ( \n",
    "    tf.data.Dataset \n",
    "    .from_tensor_slices((X_train, Y_train)) \n",
    "    .map(decode_image, num_parallel_calls=AUTO) \n",
    "    .map(partial(process_data), num_parallel_calls=AUTO) \n",
    "    .batch(32) \n",
    "    .prefetch(AUTO) \n",
    ") \n",
    "\n",
    "val_ds = ( \n",
    "    tf.data.Dataset \n",
    "    .from_tensor_slices((X_val, Y_val)) \n",
    "    .map(decode_image, num_parallel_calls=AUTO) \n",
    "    .batch(32) \n",
    "    .prefetch(AUTO) \n",
    ") \n",
    "\n",
    "# Model creation\n",
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "pre_trained_model = InceptionV3(input_shape=(128, 128, 3), weights='imagenet', include_top=False) \n",
    "for layer in pre_trained_model.layers: \n",
    "    layer.trainable = False\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('mixed7') \n",
    "last_output = last_layer.output\n",
    "\n",
    "x = layers.Flatten()(last_output) \n",
    "x = layers.Dense(256, activation='relu')(x) \n",
    "x = layers.BatchNormalization()(x) \n",
    "x = layers.Dense(256, activation='relu')(x) \n",
    "x = layers.Dropout(0.3)(x) \n",
    "x = layers.BatchNormalization()(x) \n",
    "output = layers.Dense(120, activation='softmax')(x) \n",
    "\n",
    "model = keras.Model(pre_trained_model.input, output) \n",
    "\n",
    "# Model compilation\n",
    "model.compile(optimizer='adam', loss=keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['AUC']) \n",
    "\n",
    "# Callbacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if logs.get('val_auc') > 0.99: \n",
    "            print('\\n Validation accuracy has reached up to 90%, so stopping further training.') \n",
    "            self.model.stop_training = True\n",
    "\n",
    "es = EarlyStopping(patience=3, monitor='val_auc', restore_best_weights=True) \n",
    "lr = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5, verbose=1) \n",
    "\n",
    "# Model training\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=10, verbose=1, callbacks=[es, lr, myCallback()]) \n",
    "\n",
    "# Save model\n",
    "model.save('dog_breed_classifier_model.h5')\n",
    "\n",
    "# Prediction function\n",
    "def preprocess_image(filepath):\n",
    "    img = tf.io.read_file(filepath)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [128, 128])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = tf.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "def predict_breed(model, filepath):\n",
    "    img = preprocess_image(filepath)\n",
    "    predictions = model.predict(img)\n",
    "    predicted_class = tf.argmax(predictions, axis=-1).numpy()[0]\n",
    "    return predicted_class\n",
    "\n",
    "def get_breed_name(predicted_class, label_encoder):\n",
    "    return label_encoder.inverse_transform([predicted_class])[0]\n",
    "\n",
    "# Load the saved model and label encoder\n",
    "model = keras.models.load_model('dog_breed_classifier_model.h5')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "def predict_dog_breed(model, image_path, label_encoder):\n",
    "    predicted_class = predict_breed(model, image_path)\n",
    "    breed_name = get_breed_name(predicted_class, label_encoder)\n",
    "    return breed_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "The predicted breed is: saint_bernard\n"
     ]
    }
   ],
   "source": [
    "image_path = 'C:/Users/Satvik/Pictures/Saved Pictures/dogu5.jpg'  # Replace with the path to your image\n",
    "predicted_breed = predict_dog_breed(model, image_path, label_encoder)\n",
    "print(f'The predicted breed is: {predicted_breed}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
